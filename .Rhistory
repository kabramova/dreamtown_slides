logisticMap(3, 20, c(0.2, 0.3, 0.8))
logisticMap(3.2, 20, c(0.2, 0.3, 0.8))
getwd()
setwd("dataproducts/dreamtown_slides")
getwd()
library(slidify)
library(melt)
library(ggplot2)
yeardata <- readRDS("dreamtown/data/yeardata.Rds")
yeardata <- readRDS("~/rwd/dataproducts/dreamtown/data/yeardata.Rds")
smax <- max(yeardata[,2:13])
ymax <- round_any(smax, 10, f=ceiling)
ylong <- melt(yeardata)
library(reshape2)
ylong <- melt(yeardata)
View(ylong)
View(yeardata)
setwd('/Users/katja/rwd/dataproducts/')
sun <- read.csv('sundata.csv')
sun.mean <- filter(sun, Statistic.Description == "Mean Number of Hours")
sun.small <- select(sun.mean, Country.or.Territory, Station.Name, WMO.Station.Number,
Annual, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
sun.clean <- filter(sun.small, Annual > 0)
hist(sun.clean$Annual)
stations <- read.csv('stations.flatfile', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
dms2dec <- function(coord) {
dms <- unlist(strsplit(as.character(coord), " "))
dir <- substr(dms[3],3,3)
s <- substr(dms[3],1,2)
dec <- as.numeric(dms[1]) +
as.numeric(dms[2])/60 +
as.numeric(s)/3600
#reverse for south or west coordinates
if (dir == 'S' || dir == 'W') {
dec = dec * (-1)
}
dec
}
m <- stations.small[,2:3]
n <- apply(m, c(1,2), dms2dec)
stations.small$Lat <- n[,1]
stations.small$Lng <- n[,2]
sun.mean <- filter(sun, Statistic.Description == "Mean Number of Hours")
sun.small <- select(sun.mean, Country.or.Territory, Station.Name, WMO.Station.Number,
Annual, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
sun.clean <- filter(sun.small, Annual > 0)
hist(sun.clean$Annual)
library(RCurl)
library(RJSONIO)
library(dplyr)
sun.mean <- filter(sun, Statistic.Description == "Mean Number of Hours")
sun.small <- select(sun.mean, Country.or.Territory, Station.Name, WMO.Station.Number,
Annual, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
sun.clean <- filter(sun.small, Annual > 0)
hist(sun.clean$Annual)
stations <- read.csv('stations.flatfile', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
dms2dec <- function(coord) {
dms <- unlist(strsplit(as.character(coord), " "))
dir <- substr(dms[3],3,3)
s <- substr(dms[3],1,2)
dec <- as.numeric(dms[1]) +
as.numeric(dms[2])/60 +
as.numeric(s)/3600
#reverse for south or west coordinates
if (dir == 'S' || dir == 'W') {
dec = dec * (-1)
}
dec
}
m <- stations.small[,2:3]
n <- apply(m, c(1,2), dms2dec)
stations.small$Lat <- n[,1]
stations.small$Lng <- n[,2]
sun.mean <- filter(sun, Statistic.Description == "Mean Number of Hours")
sun.small <- select(sun.mean, Country.or.Territory, Station.Name, WMO.Station.Number,
Annual, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
sun.clean <- filter(sun.small, Annual > 0)
hist(sun.clean$Annual)
stations <- read.csv('stations.flatfile', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
stations <- read.csv('stations.txt', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
View(stations)
stations <- read.csv('stations.flatfile', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
dms2dec <- function(coord) {
dms <- unlist(strsplit(as.character(coord), " "))
dir <- substr(dms[3],3,3)
s <- substr(dms[3],1,2)
dec <- as.numeric(dms[1]) +
as.numeric(dms[2])/60 +
as.numeric(s)/3600
#reverse for south or west coordinates
if (dir == 'S' || dir == 'W') {
dec = dec * (-1)
}
dec
}
m <- stations.small[,2:3]
n <- apply(m, c(1,2), dms2dec)
stations.small$Lat <- n[,1]
stations.small$Lng <- n[,2]
sun.locations <- merge(sun.clean, stations.small, by.x="WMO.Station.Number",
by.y="IndexNbr")
# "Mixed case" capitalizing - toupper(every first letter of a word)
simpleCap <- function(x) {
s <- strsplit(x, " ")[[1]]
paste(toupper(substring(s, 1, 1)), tolower(substring(s, 2)),
sep = "", collapse = " ")
}
sun.locations$Station.Name <- lapply(as.character(sun.locations$Station.Name), simpleCap)
sun.locations <- subset(sun.locations, !duplicated(sun.locations$WMO.Station.Number))
saveRDS(sun.locations, file="sunlocations.Rds")
View(sun.locations)
sun.year <- select(sun.locations, Station.Name, Jan, Feb, Mar, Apr, May, Jun,
Jul, Aug, Sep, Oct, Nov, Dec)
yeardata <- data.frame(matrix(nrow=dim(ps)[1], ncol=14))
yeardata[,1] <- rownames(pollution.small)
library(XLConnect)
pollution <- readWorksheetFromFile("who.xlsx", sheet="database", startRow=3)
colnames(pollution)[6:9] <- c("PM10.Annual.Mean", "PM10.Year", "PM10.Station.Types",
"PM10.Notes")
colnames(pollution)[10:13] <- c("PM2.5.Annual.Mean", "PM2.5.Year", "PM2.5.Station.Types",
"PM2.5.Notes")
colnames(pollution)[15] <- "Reference"
pollution.small <- select(pollution, Country, City=City.Town, PM10.Annual=PM10.Annual.Mean,
PM25.Annual=PM2.5.Annual.Mean)
pollution <- readWorksheetFromFile("who.xlsx", sheet="database", startRow=3)
colnames(pollution)[6:9] <- c("PM10.Annual.Mean", "PM10.Year", "PM10.Station.Types",
"PM10.Notes")
colnames(pollution)[10:13] <- c("PM2.5.Annual.Mean", "PM2.5.Year", "PM2.5.Station.Types",
"PM2.5.Notes")
colnames(pollution)[15] <- "Reference"
pollution.small <- select(pollution, Country, City=City.Town, PM10.Annual=PM10.Annual.Mean,
PM25.Annual=PM2.5.Annual.Mean)
yeardata[,1] <- rownames(pollution.small)
View(sun.locations)
library(plyr)
setwd('/Users/katja/rwd/dataproducts/')
sun <- read.csv('sundata.csv')
sun.mean <- filter(sun, Statistic.Description == "Mean Number of Hours")
sun.small <- select(sun.mean, Country.or.Territory, Station.Name, WMO.Station.Number,
Annual, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
sun.clean <- filter(sun.small, Annual > 0)
hist(sun.clean$Annual)
stations <- read.csv('stations.flatfile', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
View(stations.small)
View(stations)
sunFilename <- ('sunlocations.Rds')
file.exists(sunFilename)
sun.locations <- readRDS(sunFilename)
pollution <- readWorksheetFromFile("who.xlsx", sheet="database", startRow=3)
colnames(pollution)[6:9] <- c("PM10.Annual.Mean", "PM10.Year", "PM10.Station.Types",
"PM10.Notes")
colnames(pollution)[10:13] <- c("PM2.5.Annual.Mean", "PM2.5.Year", "PM2.5.Station.Types",
"PM2.5.Notes")
colnames(pollution)[15] <- "Reference"
pollution.small <- select(pollution, Country, City=City.Town, PM10.Annual=PM10.Annual.Mean,
PM25.Annual=PM2.5.Annual.Mean)
View(pollution.small)
addresses <- paste(pollution.small[,1], pollution.small[,2], sep=", ")
length(addresses)
pollution.small$City <- lapply(as.character(pollution.small$City), simpleCap)
pollution.small$City <- as.character(pollution.small$City)
addresses <- paste(pollution.small[,1], pollution.small[,2], sep=", ")
geocoded <- data.frame()
startindex <- 1
getGeoDetails <- function(address){
# use the gecode function to query google servers
geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
# now extract the bits that we need from the returned list
answer <- data.frame(lat=NA, long=NA, accuracy=NA, formatted_address=NA, address_type=NA, status=NA)
answer$status <- geo_reply$status
#if we are over the query limit - want to pause for an hour
while(geo_reply$status == "OVER_QUERY_LIMIT"){
print("OVER QUERY LIMIT - Pausing for 1 hour at:")
time <- Sys.time()
print(as.character(time))
Sys.sleep(60*60)
geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
answer$status <- geo_reply$status
}
# return Na's if we didn't get a match:
if (geo_reply$status != "OK"){
return(answer)
}
# else, extract what we need from the Google server reply into a dataframe:
answer$lat <- geo_reply$results[[1]]$geometry$location$lat
answer$long <- geo_reply$results[[1]]$geometry$location$lng
# if (length(geo_reply$results[[1]]$types) > 0){
#     answer$accuracy <- geo_reply$results[[1]]$types[[1]]
# }
# answer$address_type <- paste(geo_reply$results[[1]]$types, collapse=',')
# answer$formatted_address <- geo_reply$results[[1]]$formatted_address
return(answer)
}
library(ggmap)
result <- getGeoDetails(addresses[1])
print(result$status)
result$index <- ii
result$index <- 1
geocoded <- rbind(geocoded, result)
geocoded
length(addresses)
sunFilename <- ('sunlocations.Rds')
file.exists(sunFilename)
# get data on annual number of sunshine hours
setwd('/Users/katja/rwd/dataproducts/')
sun <- read.csv('sundata.csv')
# use only clean data with comparable statistic
sun.mean <- filter(sun, Statistic.Description == "Mean Number of Hours")
sun.small <- select(sun.mean, Country.or.Territory, Station.Name, WMO.Station.Number,
Annual, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
# hist(sun.clean$Annual)  # some entries are negative for missing data
sun.clean <- filter(sun.small, Annual > 0)
# get meteorological stations information
stations <- read.csv('stations.flatfile', sep='\t')
stations.small <- select(stations, IndexNbr, Latitude, Longitude)
# function for converting between dms and decimal coordinate formats
dms2dec <- function(coord) {
dms <- unlist(strsplit(as.character(coord), " "))
dir <- substr(dms[3],3,3)
s <- substr(dms[3],1,2)
dec <- as.numeric(dms[1]) +
as.numeric(dms[2])/60 +
as.numeric(s)/3600
# reverse for south or west coordinates
if (dir == 'S' || dir == 'W') {
dec = dec * (-1)
}
dec
}
# convert formats
m <- stations.small[,2:3]
n <- apply(m, c(1,2), dms2dec)
stations.small$Lat <- n[,1]
stations.small$Lng <- n[,2]
# add station coordinates to the sunshine data
sun.locations <- merge(sun.clean, stations.small, by.x="WMO.Station.Number",
by.y="IndexNbr")
# "mixed case" capitalizing, i.e. toupper(every first letter of a word)
simpleCap <- function(x) {
s <- strsplit(x, " ")[[1]]
paste(toupper(substring(s, 1, 1)), tolower(substring(s, 2)),
sep = "", collapse = " ")
}
# clean station names
sun.locations$Station.Name <- lapply(as.character(sun.locations$Station.Name), simpleCap)
sun.locations <- subset(sun.locations, !duplicated(sun.locations$WMO.Station.Number))
sun.locations$Station.Name <- as.character(sun.locations$Station.Name)
# save sunshine data
saveRDS(sun.locations, file="sunlocations.Rds")
sun.locations <- readRDS(sunFilename)
View(sun.locations)
# define a function that will process googles server responses for us.
getGeoDetails <- function(address){
# use the gecode function to query google servers
geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
# now extract the bits that we need from the returned list
answer <- data.frame(lat=NA, long=NA, status=NA)
answer$status <- geo_reply$status
#if we are over the query limit - want to pause for an hour
while(geo_reply$status == "OVER_QUERY_LIMIT"){
print("OVER QUERY LIMIT - Pausing for 1 hour at:")
time <- Sys.time()
print(as.character(time))
Sys.sleep(60*60)
geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
answer$status <- geo_reply$status
}
# return Na's if we didn't get a match:
if (geo_reply$status != "OK"){
return(answer)
}
# else, extract what we need from the Google server reply into a dataframe:
answer$lat <- geo_reply$results[[1]]$geometry$location$lat
answer$lng <- geo_reply$results[[1]]$geometry$location$lng
return(answer)
}
# Geocode data if necessary
pollutionFilename <- ('pollution.Rds')
file.exists(pollutionFilename)
pollution <- readWorksheetFromFile("who.xlsx", sheet="database", startRow=3)
colnames(pollution)[6:9] <- c("PM10.Annual.Mean", "PM10.Year", "PM10.Station.Types",
"PM10.Notes")
colnames(pollution)[10:13] <- c("PM2.5.Annual.Mean", "PM2.5.Year", "PM2.5.Station.Types",
"PM2.5.Notes")
colnames(pollution)[15] <- "Reference"
pollution.small <- select(pollution, Country, City=City.Town, PM10.Annual=PM10.Annual.Mean,
PM25.Annual=PM2.5.Annual.Mean)
pollution.small$City <- lapply(as.character(pollution.small$City), simpleCap)
pollution.small$City <- as.character(pollution.small$City)
addresses <- paste(pollution.small[,1], pollution.small[,2], sep=", ")
# initialise a dataframe to hold the results
geocoded <- data.frame()
# find out where to start in the address list (if the script was interrupted before):
startindex <- 1
# if a temp file exists - load it up and count the rows!
tempfilename <- 'temp_geocoded.rds'
saveRDS(sun.locations, sunFilename)
library(ggmap)
source('~/rwd/dataproducts/project.R', echo=TRUE)
file.exists(tempfilename)
geocoded <- readRDS(tempfilename)
startindex <- nrow(geocoded)
print(startindex)
addresses[160]
addresses[159]
result <- getGeoDetails(addresses[160])
print(result)
View(geocoded)
geocoded2 <- select(geocoded, lat, lng, status, index)
View(geocoded2)
saveRDS(geocoded2, tempfilename)
getGeoDetails <- function(address){
# use the gecode function to query google servers
geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
# now extract the bits that we need from the returned list
answer <- data.frame(lat=NA, lng=NA, status=NA)
answer$status <- geo_reply$status
#if we are over the query limit - want to pause for an hour
while(geo_reply$status == "OVER_QUERY_LIMIT"){
print("OVER QUERY LIMIT - Pausing for 1 hour at:")
time <- Sys.time()
print(as.character(time))
Sys.sleep(60*60)
geo_reply = geocode(address, output='all', messaging=TRUE, override_limit=TRUE)
answer$status <- geo_reply$status
}
# return Na's if we didn't get a match:
if (geo_reply$status != "OK"){
return(answer)
}
# else, extract what we need from the Google server reply into a dataframe:
answer$lat <- geo_reply$results[[1]]$geometry$location$lat
answer$lng <- geo_reply$results[[1]]$geometry$location$lng
return(answer)
}
result <- getGeoDetails(addresses[160])
result
addresses[160]
addresses[160:170]
source('~/rwd/dataproducts/project.R', echo=TRUE)
length(addresses)
length(pollution.small)
View(pollution.small)
dim(pollution.small)
geocoded <- readRDS(tempfilename)
dim(geocoded)
View(geocoded)
nrow(geocoded)
tail(geocoded)
geocoded2 <- rbind(geocoded[1:159,], geocoded[161:2973,]
)
dim(geocoded2)
View(geocoded2)
row.names(geocoded2) <- geocoded2$index
View(geocoded2)
tail(geocoded2)
geocoded <- geocoded2
saveRDS(geocoded, tempfilename)
source('~/rwd/dataproducts/project.R', echo=TRUE)
geocoded <- readRDS(tempfilename)
tail(geocoded)
length(addresses)
startindex <- length(addresses)
startindex
seq(startindex, length(addresses))
source('~/rwd/dataproducts/project.R', echo=TRUE)
tail(geocoded)
geocoded <- geocoded[1:2972,]
tail(geocoded)
saveRDS(geocoded, tempfilename)
source('~/rwd/dataproducts/project.R', echo=TRUE)
pollutionFilename <- ('pollution.Rds')
file.exists(pollutionFilename)
pollution <- readRDS(pollutionFilename)
View(pollution)
View(sun)
table(sun$Statistic.Description)
sl <- select(sun.locations, Lng, Lat)
ps <- select(pollution, Lng, Lat)
closest.idx <- numeric(length=dim(ps)[1])
for (el in 1:dim(ps)[1]){
d <- distGeo(ps[el,], sl)
min_dist <- which.min(d)
if (length(min_dist)==0){
closest.idx[el] <- NA
}
else {closest.idx[el] <- min_dist}
}
??distGeo
library(geosphere)
for (el in 1:dim(ps)[1]){
d <- distGeo(ps[el,], sl)
min_dist <- which.min(d)
if (length(min_dist)==0){
closest.idx[el] <- NA
}
else {closest.idx[el] <- min_dist}
}
sun.locations[closest.idx[2973],]
length(closest.idx)
sun.locations[closest.idx[2972],]
pollution.small[2972,]
alldata <- pollution.small
for (el in 1:dim(ps)[1]){
alldata$Sunshine[el] <- sun.locations$Annual[closest.idx[el]]
}
View(alldata)
alldata.final <- alldata[complete.cases(alldata),]
alldata[!complete.cases(alldata),]
sun.year <- select(sun.locations, Station.Name, Jan, Feb, Mar, Apr, May, Jun,
Jul, Aug, Sep, Oct, Nov, Dec)
yeardata <- data.frame(matrix(nrow=dim(ps)[1], ncol=14))
yeardata[,1] <- rownames(pollution.small)
View(yeardata)
for (el in 1:dim(ps)[1]){
yeardata[el,2:13] <- sun.year[closest.idx[el],]
}
warnings()
yeardata <- data.frame(matrix(nrow=dim(ps)[1], ncol=14))
yeardata[,1] <- rownames(pollution.small)
for (el in 1:dim(ps)[1]){
yeardata[el,2:14] <- sun.year[closest.idx[el],]
}
colnames(yeardata) <- c("ids", "Station.Name", "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul",
"Aug", "Sep", "Oct", "Nov", "Dec")
View(yeardata)
View(sun.locations)
yeardata.final <- yeardata[complete.cases(alldata),]
yeardata.final[yeardata.final<0] <- 0
saveRDS(alldata.final, file="alldata.Rds")
saveRDS(yeardata.final, file="yeardata.Rds")
getwd()
setwd('dreamtown_slies')
setwd('dreamtown_slides')
View(yeardata)
yeardata$Station.Name==Madrid
View(alldata.final)
alldata.final[alldata.final$Country==Spain]
alldata.final[alldata.final$Country==Spain,]
alldata.final[alldata.final$Country==France,]
alldata.final[alldata.final$Country==Italy,]
alldata.final[alldata.final$Country=='Spain',]
alldata.final[alldata.final$Country=='Spain',2]
ylong <- melt(yeardata)
View(ylong)
ggplot(ylong[ylong$Station.Name=='Madrid',], aes(x=variable, y=value)) + geom_bar(stat="identity") + xlab("Month") + ylab("Hours") + ggtitle("Sunshine hours by month") + ylim(0, 450)
ylong[ylong$Station.Name=='Madrid',]
View(yeardata.final)
yeardata.final[yeardata.final$Station.Name=='Madrid',]
yeardata.final[yeardata.final$Station.Name=='Madrid',3]
yeardata.final[yeardata.final$Station.Name=='Palma De Mallorca',3]
View(sun.locations)
sun.year <- select(sun.locations, Country.Or.Territory, Station.Name, Jan, Feb,
Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
sun.year <- select(sun.locations, Country.or.Territory, Station.Name, Jan, Feb,
Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec)
yeardata <- data.frame(matrix(nrow=dim(ps)[1], ncol=15))
yeardata[,1] <- rownames(pollution.small)
for (el in 1:dim(ps)[1]){
yeardata[el,2:15] <- sun.year[closest.idx[el],]
}
colnames(yeardata) <- c("ids", "Country", "Station.Name", "Jan", "Feb", "Mar",
"Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
yeardata.final <- yeardata[complete.cases(alldata),]
yeardata.final[yeardata.final<0] <- 0
View(yeardata.final)
View(sun.year)
yeardata <- data.frame(matrix(nrow=dim(ps)[1], ncol=15))
yeardata[,1] <- rownames(pollution.small)
View(yeardata)
View(sun.year)
sun.year[closest.idx[1],]
for (el in 1:dim(ps)[1]){
yeardata[el,2:15] <- sun.year[closest.idx[el],]
}
View(yeardata)
str(sun.year)
sun.year$Country.or.Territory <- as.character(sun.year$Country.or.Territory)
yeardata <- data.frame(matrix(nrow=dim(ps)[1], ncol=15))
yeardata[,1] <- rownames(pollution.small)
for (el in 1:dim(ps)[1]){
yeardata[el,2:15] <- sun.year[closest.idx[el],]
}
colnames(yeardata) <- c("ids", "Country", "Station.Name", "Jan", "Feb", "Mar",
"Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
View(yeardata)
yeardata.final <- yeardata[complete.cases(alldata),]
yeardata.final[yeardata.final<0] <- 0
View(yeardata.final)
yeardata.final[yeardata.final$Country==Spain,]
yeardata.final[yeardata.final$Country=='Spain',]
yeardata.final[yeardata.final$Country=='SPAIN',]
yeardata.final[yeardata.final$Country=='FRANCE',]
yeardata.final[yeardata.final$Country=='ITALY',]
yeardata.final[yeardata.final$Country=='ITALY',3]
unique(yeardata.final[yeardata.final$Country=='ITALY',3])
unique(yeardata.final[yeardata.final$Country=='FRANCE',3])
unique(yeardata.final[yeardata.final$Country=='ARGENTINA',3])
unique(yeardata.final[yeardata.final$Country=='BRAZIL',3])
saveRDS(alldata.final, file="alldata.Rds")
saveRDS(yeardata.final, file="yeardata.Rds")
yeardata <- readRDS("yeardata.Rds")
ylong <- melt(yeardata)
ggplot(ylong[ylong$Station.Name=='Sao Paulo',], aes(x=variable, y=value)) + geom_bar(stat="identity") + xlab("Month") + ylab("Hours") + ggtitle("Sunshine hours by month") + ylim(0, 450)
ggplot(ylong[ylong$Station.Name=='Sao Paulo',], aes(x=variable, y=value)) + geom_bar(stat="identity") + xlab("Month") + ylab("Hours") +
ggtitle("Sunshine hours by month in Sao Paulo, Brazil") + ylim(0, 450)
